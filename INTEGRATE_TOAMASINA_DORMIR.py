#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ INT√âGRATION S√âCURIS√âE TOAMASINA - Phase 2: DORMIR
Int√®gre les 15 fiches h√©bergements dans lieux.js de mani√®re s√©curis√©e.
"""

import json
import re
import shutil
from pathlib import Path
from datetime import datetime

PROJECT_ROOT = Path(__file__).parent
LIEUX_FILE = PROJECT_ROOT / 'data' / 'lieux.js'
NEW_DATA_FILE = PROJECT_ROOT / 'toamasina_dormir.json'

def create_backup():
    """Cr√©e un backup de lieux.js"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_file = PROJECT_ROOT / f'data/lieux_backup_{timestamp}.js'
    shutil.copy2(LIEUX_FILE, backup_file)
    print(f"‚úÖ Backup cr√©√©: {backup_file.name}")
    return backup_file

def load_lieux_data():
    """Charge les donn√©es depuis lieux.js"""
    with open(LIEUX_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    match = re.search(r'window\.LIEUX_DATA\s*=\s*(\[.*\]);', content, re.DOTALL)
    if not match:
        raise ValueError("Impossible de trouver window.LIEUX_DATA")
    
    return json.loads(match.group(1)), content

def load_new_locations():
    """Charge les nouvelles fiches depuis le JSON"""
    with open(NEW_DATA_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def validate_location(loc):
    """Valide qu'une fiche a tous les champs requis"""
    required = ['nom', 'ville', 'description', 'tags', 'prix', 'prixNum', 'lat', 'lng', 'note', 'type']
    for field in required:
        if field not in loc:
            return False, f"Champ manquant: {field}"
    
    if 'toamasina' not in loc['tags']:
        return False, "Tag 'toamasina' manquant"
    
    if 'dormir' not in loc['tags']:
        return False, "Tag 'dormir' manquant"
    
    budget_tags = [t for t in loc['tags'] if t.startswith('budget_')]
    if len(budget_tags) != 1:
        return False, f"Doit avoir exactement 1 tag budget, trouv√© {len(budget_tags)}"
    
    return True, "OK"

def integrate_locations():
    """Int√®gre les nouvelles fiches dans lieux.js"""
    
    print("üéØ INT√âGRATION TOAMASINA - PHASE 2: DORMIR")
    print("=" * 80)
    
    # 1. Backup
    backup_file = create_backup()
    
    # 2. Charger donn√©es existantes
    print("\nüìÇ Chargement donn√©es existantes...")
    existing_data, original_content = load_lieux_data()
    print(f"   Fiches existantes: {len(existing_data)}")
    
    # 3. Charger nouvelles fiches
    print("\nüì• Chargement nouvelles fiches...")
    new_locations = load_new_locations()
    print(f"   Nouvelles fiches: {len(new_locations)}")
    
    # 4. Validation
    print("\n‚úì Validation des fiches...")
    valid_count = 0
    errors = []
    for i, loc in enumerate(new_locations, 1):
        is_valid, msg = validate_location(loc)
        if is_valid:
            valid_count += 1
        else:
            errors.append(f"  Fiche {i} ({loc.get('nom', 'SANS NOM')}): {msg}")
    
    if errors:
        print(f"   ‚ùå {len(errors)} erreurs d√©tect√©es:")
        for error in errors:
            print(error)
        return False
    
    print(f"   ‚úÖ {valid_count}/{len(new_locations)} fiches valides")
    
    # 5. Attribuer IDs et images
    print("\nüî¢ Attribution des IDs et chemins images...")
    next_id = max(lieu['id'] for lieu in existing_data) + 1
    for i, loc in enumerate(new_locations):
        loc['id'] = next_id + i
        # Image placeholder
        loc['image'] = 'images/placeholder-hotel.jpg'
    
    print(f"   Premier ID: {next_id}")
    print(f"   Dernier ID: {next_id + len(new_locations) - 1}")
    
    # 6. Fusionner
    print("\nüîó Fusion des donn√©es...")
    merged_data = existing_data + new_locations
    print(f"   Total apr√®s fusion: {len(merged_data)} fiches")
    
    # 7. Sauvegarder
    print("\nüíæ Sauvegarde dans lieux.js...")
    
    match = re.search(r'(window\.LIEUX_DATA\s*=\s*)\[.*\];', original_content, re.DOTALL)
    if not match:
        print("   ‚ùå Erreur: Impossible de trouver window.LIEUX_DATA")
        return False
    
    new_json = json.dumps(merged_data, ensure_ascii=False, indent=2)
    new_content = original_content[:match.start(1)] + match.group(1) + new_json + ';' + original_content[match.end():]
    
    with open(LIEUX_FILE, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print("   ‚úÖ Fichier lieux.js mis √† jour")
    
    # 8. Statistiques finales
    print("\n" + "=" * 80)
    print("üìä R√âSUM√â")
    print("=" * 80)
    print(f"   Fiches AVANT: {len(existing_data)}")
    print(f"   Fiches AJOUT√âES: {len(new_locations)}")
    print(f"   Fiches APR√àS: {len(merged_data)}")
    print(f"   Backup: {backup_file.name}")
    print("\n‚úÖ Phase 2 termin√©e !")
    print(f"\nüìä PROGRESSION TOAMASINA: 30/65 fiches cr√©√©es")
    print("   ‚úÖ Manger: 15/15")
    print("   ‚úÖ Dormir: 15/15")
    print("   ‚è≥ Explorer: 0/20")
    print("   ‚è≥ Sortir: 0/10")
    print("   ‚è≥ Spots: 0/5")
    
    return True

if __name__ == '__main__':
    success = integrate_locations()
    exit(0 if success else 1)
